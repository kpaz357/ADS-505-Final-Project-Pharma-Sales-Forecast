{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09334be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90abf408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using processed dir: C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\n",
      "daily   -> C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\\salesdaily_clean.csv\n",
      "weekly  -> C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\\salesweekly_clean.csv\n",
      "monthly -> C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\\salesmonthly_clean.csv\n",
      "hourly  -> C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\\saleshourly_clean.csv\n",
      "daily: (2106, 13) | cols: ['datum', 'M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B'] ...\n",
      "weekly: (302, 9) | cols: ['datum', 'M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B'] ...\n",
      "monthly: (70, 9) | cols: ['datum', 'M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B'] ...\n",
      "hourly: (50532, 13) | cols: ['datum', 'M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B'] ...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Find the processed directory automatically\n",
    "CANDIDATES = [\n",
    "    Path.cwd() / \"data\" / \"processed\",\n",
    "    Path.home() / \"Documents\" / \"ADS-505-Final-Project-Pharma-Sales-Forecast\" / \"data\" / \"processed\",\n",
    "    Path(r\"C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\"),\n",
    "]\n",
    "\n",
    "def pick_processed_dir(candidates):\n",
    "    for d in candidates:\n",
    "        if d.exists() and any(d.glob(\"sales*clean*\")):\n",
    "            print(f\"Using processed dir: {d}\")\n",
    "            return d\n",
    "    raise FileNotFoundError(\"Could not locate a 'data/processed' folder containing sales*clean files.\")\n",
    "\n",
    "PROCESSED = pick_processed_dir(CANDIDATES)\n",
    "\n",
    "# Resolve filenames regardless of extension / slight name differences\n",
    "def resolve_file(stem: str) -> Path | None:\n",
    "    # Try exact common extensions first\n",
    "    for ext in (\".csv\", \".xlsx\", \".CSV\", \".XLSX\"):\n",
    "        p = PROCESSED / f\"{stem}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # Fallback: fuzzy match (e.g., 'salesdaily_clean*')\n",
    "    hits = sorted(PROCESSED.glob(f\"{stem}*\"))\n",
    "    return hits[0] if hits else None\n",
    "\n",
    "files = {\n",
    "    \"daily\":   resolve_file(\"salesdaily_clean\"),\n",
    "    \"weekly\":  resolve_file(\"salesweekly_clean\"),\n",
    "    \"monthly\": resolve_file(\"salesmonthly_clean\"),\n",
    "    \"hourly\":  resolve_file(\"saleshourly_clean\"),\n",
    "}\n",
    "\n",
    "for k, fp in files.items():\n",
    "    print(f\"{k:<7} ->\", fp if fp else \"NOT FOUND\")\n",
    "\n",
    "# 3) Helper to read CSV or Excel uniformly\n",
    "def read_any(fp: Path, parse_dates=(\"datum\",)):\n",
    "    if fp.suffix.lower() == \".csv\":\n",
    "        return pd.read_csv(fp, parse_dates=list(parse_dates))\n",
    "    elif fp.suffix.lower() in {\".xlsx\", \".xls\"}:\n",
    "        return pd.read_excel(fp, parse_dates=list(parse_dates))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {fp.suffix}\")\n",
    "\n",
    "# Example loads \n",
    "daily   = read_any(files[\"daily\"])   if files[\"daily\"]   else None\n",
    "weekly  = read_any(files[\"weekly\"])  if files[\"weekly\"]  else None\n",
    "monthly = read_any(files[\"monthly\"]) if files[\"monthly\"] else None\n",
    "hourly  = read_any(files[\"hourly\"])  if files[\"hourly\"]  else None\n",
    "\n",
    "for name, df in [(\"daily\", daily), (\"weekly\", weekly), (\"monthly\", monthly), (\"hourly\", hourly)]:\n",
    "    if df is not None:\n",
    "        print(f\"{name}: {df.shape} | cols: {list(df.columns)[:6]} ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b3b078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2076, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>M01AB</th>\n",
       "      <th>M01AE</th>\n",
       "      <th>N02BA</th>\n",
       "      <th>N02BE</th>\n",
       "      <th>N05B</th>\n",
       "      <th>N05C</th>\n",
       "      <th>R03</th>\n",
       "      <th>R06</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_sales_lag_1</th>\n",
       "      <th>total_sales_lag_7</th>\n",
       "      <th>total_sales_lag_30</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_std_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>84.65</td>\n",
       "      <td>47.68</td>\n",
       "      <td>81.80</td>\n",
       "      <td>48.47</td>\n",
       "      <td>51.915714</td>\n",
       "      <td>15.821377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>39.70</td>\n",
       "      <td>84.65</td>\n",
       "      <td>34.01</td>\n",
       "      <td>107.00</td>\n",
       "      <td>52.322857</td>\n",
       "      <td>16.729208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>32.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.90</td>\n",
       "      <td>39.70</td>\n",
       "      <td>56.81</td>\n",
       "      <td>91.35</td>\n",
       "      <td>53.135714</td>\n",
       "      <td>15.803739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.93</td>\n",
       "      <td>64.90</td>\n",
       "      <td>58.52</td>\n",
       "      <td>66.10</td>\n",
       "      <td>54.291429</td>\n",
       "      <td>16.401714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-05</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>6.2</td>\n",
       "      <td>32.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.62</td>\n",
       "      <td>69.93</td>\n",
       "      <td>39.33</td>\n",
       "      <td>58.20</td>\n",
       "      <td>55.921429</td>\n",
       "      <td>17.426910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datum  M01AB  M01AE  N02BA  N02BE  N05B  N05C   R03  R06  Year  ...  \\\n",
       "0 2014-02-01   4.33   4.32    5.0   43.0  13.0   1.0  14.0  0.0  2014  ...   \n",
       "1 2014-02-02   7.00   3.00    0.2   13.5   6.0   2.0   8.0  0.0  2014  ...   \n",
       "2 2014-02-03   5.00   1.00    8.5   32.4  16.0   1.0   1.0  0.0  2014  ...   \n",
       "3 2014-02-04   1.33   3.00    7.0   30.6   8.0   1.0  17.0  2.0  2014  ...   \n",
       "4 2014-02-05   3.00   4.02    6.2   32.4  15.0   1.0   1.0  1.0  2014  ...   \n",
       "\n",
       "   month  day  dayofweek  is_weekend  total_sales  total_sales_lag_1  \\\n",
       "0      2    1          5           1        84.65              47.68   \n",
       "1      2    2          6           1        39.70              84.65   \n",
       "2      2    3          0           0        64.90              39.70   \n",
       "3      2    4          1           0        69.93              64.90   \n",
       "4      2    5          2           0        63.62              69.93   \n",
       "\n",
       "   total_sales_lag_7  total_sales_lag_30  rolling_mean_7  rolling_std_7  \n",
       "0              81.80               48.47       51.915714      15.821377  \n",
       "1              34.01              107.00       52.322857      16.729208  \n",
       "2              56.81               91.35       53.135714      15.803739  \n",
       "3              58.52               66.10       54.291429      16.401714  \n",
       "4              39.33               58.20       55.921429      17.426910  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Work on daily sales data\n",
    "df = daily.copy()\n",
    "\n",
    "# Convert date column\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "df = df.sort_values('datum')\n",
    "\n",
    "# Create temporal features\n",
    "df['year'] = df['datum'].dt.year\n",
    "df['month'] = df['datum'].dt.month\n",
    "df['day'] = df['datum'].dt.day\n",
    "df['dayofweek'] = df['datum'].dt.dayofweek\n",
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Aggregate total sales\n",
    "df['total_sales'] = df[['M01AB', 'M01AE', 'N02BA', 'N02BE', 'N05B', 'N05C', 'R03', 'R06']].sum(axis=1)\n",
    "\n",
    "# Lag and rolling features (example)\n",
    "for lag in [1, 7, 30]:\n",
    "    df[f'total_sales_lag_{lag}'] = df['total_sales'].shift(lag)\n",
    "\n",
    "df['rolling_mean_7'] = df['total_sales'].shift(1).rolling(window=7).mean()\n",
    "df['rolling_std_7'] = df['total_sales'].shift(1).rolling(window=7).std()\n",
    "\n",
    "# Drop missing rows created by shifts\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e980111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1795, 24), Test: (281, 24)\n"
     ]
    }
   ],
   "source": [
    "# Time-based split\n",
    "cutoff = '2019-01-01'\n",
    "train = df[df['datum'] < cutoff].copy()\n",
    "test = df[df['datum'] >= cutoff].copy()\n",
    "\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e937215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: C:\\Users\\kiara\\Documents\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\n",
      " Feature-engineered train/test saved.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Reuse the processed dir from the files you already loaded\n",
    "# (files['daily'] is the full path to salesdaily_clean.csv)\n",
    "out_dir = Path(files['daily']).parent   # -> ...\\ADS-505-Final-Project-Pharma-Sales-Forecast\\data\\processed\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Saving to:\", out_dir)\n",
    "\n",
    "# save\n",
    "train.to_csv(out_dir / \"salesdaily_train_fe.csv\", index=False)\n",
    "test.to_csv(out_dir / \"salesdaily_test_fe.csv\", index=False)\n",
    "print(\" Feature-engineered train/test saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33779a3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'c:\\Users\\kiara\\Downloads\\data\\processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m out_dir = Path.cwd() / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msalesdaily_train_fe.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test.to_csv(out_dir / \u001b[33m\"\u001b[39m\u001b[33msalesdaily_test_fe.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFeature-engineered train/test saved \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'c:\\Users\\kiara\\Downloads\\data\\processed'"
     ]
    }
   ],
   "source": [
    "out_dir = Path.cwd() / \"data\" / \"processed\"\n",
    "train.to_csv(out_dir / \"salesdaily_train_fe.csv\", index=False)\n",
    "test.to_csv(out_dir / \"salesdaily_test_fe.csv\", index=False)\n",
    "print(\"Feature-engineered train/test saved \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
